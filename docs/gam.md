# GAMs

## Overview

GAM (generalized additive model) is a non-parametric model to predict the response variable given a spline function of predictors. A spline function is a smooth curve, composed by multiple polynomial functions, which are called B-spline or basis function, connected at certain points (knots). Denote response variable as $y_i$, predictor as $x_i$, spline function $f(.)$, the relation between $y_i$ and $x_i$ is:

```math

E(y_i) = g^{-1}(f(x_i))

```
where $g^{-1}(.)$ is a link function and $\beta_0$ is an intercept.

### Spline function
Common choices of spline functions include cubic splines, thin plate regression splines, and penalized splines, etc. See more options [here](https://cran.r-project.org/web/packages/mgcv/mgcv.pdf#Rfn.smooth.terms). Any spline function is a linear combination of B-splines, and can be expressed as a weighted sum of B-splines. Assume $f$ is a spline function connected by $K$ knots, we have:
```math
\begin{align}
f(x_i) = \sum_{m=1}^{M}\beta_mB_{m,p}(x_i)
\end{align}
```
where $B_{m,p}(x)$ is the value evaluated by the $m^{th}$ basis function of order $p$ at $x_i$, and $\beta_m$ is the weight assigned to $B_{m,p}(.)$. The relationship between $M, p, K$ is:
$$
M =K - p - 1
$$

#### B-spline
B-spline is the building block of a spline function, thus it is also called basis function. B-spline is a piecewise polynomial defined by the order of degree $p$ and the positions of knots $x_k, k = 1, 2, ...K$. When $p=0$,
$$
B_{k,0}(x) = \begin{cases}
1  &x_{k} < x ≤ x_{k+1}\\
0 &otherwise
\end{cases}
$$
B-spline with higher order of degree is calculated by $B_{k,0}$ through [Cox-de Boor formula](https://en.wikipedia.org/wiki/B-spline#Properties):
$$
B_{k,p}(x) = \frac{x-x_k}{x_{k+p}-x_k}B_{k,p-1}(x) + \frac{x_{k+p+1}-x}{x_{k+p+1}-x_{k+1}}B_{k+1,p-1}(x)
$$

Given the number of knots or the location of knots, and the order of B-spline, a spline function can be generated by a weighted linear combination of B-splines using software package. For example, `scipy.interpolate.make_lsq_splines()` follows these rules:

1. Repetitive knot location at the beginning and end of $x$ with number of knots = $p + 1$, these are called boundary knots.
2. Expect the number of B-spline functions to be: $K-p-1$
3. Each basis function integrates to 1 in their local support.

## Bayesian framework

We use Bayesian framework to fit the GAM model. We rewrite Equation (1) in matrix form, which is:

```math

E(y) = g^{-1}(X\beta)

```

**$y$** is a vector of observed vaccination coverage, $X$ is the design matrix of basis function with $N \times M$ dimension with rows are data point $x$, and columns are basis function $B$. $N$ is the number of data points and $M$ is the number of basis functions used. The element in $X$ is the value of the basis function $B_m$ evaluated at the predictor $x_i$,

$$
X_{i, m} = B_m(x_{i})
$$

**$\beta$** is a vector of coefficients that control how much influence each basis function has on the fit of spline function $f(x_i)$. It will be estimated in model fitting. We assume $y$ is normally distributed and use identity link function for now, which is: $X\beta = E(y)$.

### Population-level effect

#### Model structure

```math
\begin{align*}
p(\beta,\lambda,\sigma |y) & ∝ p(y |\beta,\sigma)p(\beta|\lambda, \sigma)p(\lambda)p(\sigma) \\
p(y|\beta, \sigma) & \sim MultiNormal(X\beta, \sigma I) \\
p(\beta|\lambda, \sigma) & \sim MultiNormal(0, S^{-1}(\sigma/\lambda)) \\
p(\lambda) & \sim Gamma(shape=1.0,rate=1.0) \\
p(\sigma) & \sim Exp(40)
\end{align*}
```
The parameters to estimate are $\beta, \lambda, \sigma$. Their full conditional posterior distributions can be derived. Here $\lambda$ is indepdent from $\beta$ and $\sigma$, $\sigma$ is independent from $\beta$ and $\lambda$, while $\beta$ is dependent on $\lambda$ and $\sigma$. We use empirical Bayes approach to derive the prior of $\beta$.

#### Deriving prior of $\beta$

We assume data $y$ follows normal distribution with covariance matrix $\sigma I$.
$$
Y \sim N(X\beta, \sigma I) \\
$$
Instead of directly minimizing $||y - X\beta||$, we add a term to penalize the wiggliness of the spline. The target function to minimize becomes:

$$
\hat{\beta} = argmin\{||y-X\beta|| + \lambda \int f^{(k-1)}(x)^2 dx\}
$$

$f^{(k-1)}$ is the $(k-1)^{th}$ derivative of the spline function with order of $k$. $\int f^{(k-1)}(x)^2 dx$ measures the wiggleness of the spline function for the entire range of covariate $x$. $\lambda$ is a coefficient that controls how much penalization is imposed in this function, and will be estimated.

We can rewrite the function to minimize in pure matrix form:

$$
\hat{\beta} = argmin\{||y-X\beta|| + \lambda\beta^TS\beta\}
$$

where $S$ is called penalty matrix, and

$$
S_{ij} = \int{B''_i(x)B''_j(x)dx}
$$

Multiply $-\frac{1}{2\sigma}$ to get the form of normal likelihood function of $y$, the minimization problem becomes maximization:

$$
\hat{\beta} = argmax\{-||y-X\beta||/(2\sigma) - \lambda\beta^TS\beta/(2\sigma)\}
$$
which is proportional to:
$$
log\ p(y|\beta,\sigma) - \lambda\beta^TS\beta/(2\sigma)
$$

Exponentiating the function, we have:

```math
p(y|\beta)\cdot exp(-\lambda\beta^TS\beta/(2\sigma))
```

Using empirical Bayes approach, we can derive:

$$
\hat{\beta} ∝ p(y|\beta, \sigma) \cdot exp(-\lambda\beta^TS\beta/(2\sigma))
$$

to have $\beta \sim N(0, S^{-1}(\sigma/\lambda))$. This is the prior of $\beta$ and needs to be estimated from data.
